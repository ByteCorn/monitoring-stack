global:
  scrape_interval: 15s # интервал сбора данных каждые 15 секунд
  scrape_timeout: 10s
  evaluation_interval: 15s # проверять правила каждые 15 секунд

# оповещения
alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

# правила
rule_files:
  - 'alerts.yml'

# конфигурация сбора данных, содержащая ровно одну конечную точку для сбора данных,
# в нашем случае это сам Prometheus
scrape_configs:
  # название задания соответствует имени целевого узла и добавляется в качестве метки
  - job_name: 'neural'
    static_configs:
      - targets:
        - 'prometheus:9090'      # сам себя
        - 'node-exporter:9100'   # метрики хоста
        - 'dcgm-exporter:9400'   # метрики GPU
        # Эти сервисы в другом стеке, идем через шлюз хоста
        - 'host.docker.internal:9833' # Graylog из стека логирования
        - 'host.docker.internal:9216' # MongoDB из стека логирования
